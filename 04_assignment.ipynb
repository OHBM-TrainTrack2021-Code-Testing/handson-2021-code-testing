{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJpU38rFAZSEKypy7z8b77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lindajune/handson-2021-code-testing/blob/main/04_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2yb7LFlnD5u"
      },
      "source": [
        "#Assignment One (debugger to run till completion)\n",
        "\n",
        "---\n",
        "This assignment covers the basic steps in running regression analysis with Python. Please test the code by identifying its errors and/or exceptions to make it run to completion. Hope this would help you get familiar with python coding. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWFzMK5qonwW"
      },
      "source": [
        "## 1. Simple Linear regression with scikit-learn\n",
        "- about [scikit-learn](https://scikit-learn.org/stable/getting_started.html): it is probably the most useful library for machine learning in Python. The **sklearn** library contains a lot of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction.\n",
        "\n",
        "- when sucessfully run: intercept should be -0.572, the regression coeffcient should be 2.019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IImYydOStvIH"
      },
      "source": [
        "## create data\n",
        "import matplotlib.pyplot as plt\n",
        "rng = np.random.RandomState(20)\n",
        "x = 10*rng.rand(50)\n",
        "y = 2*x-1+rng.rand(50)\n",
        "\n",
        "## define the linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model\n",
        "\n",
        "## model fitting\n",
        "model.fit(x,y);\n",
        "\n",
        "## display the parameters\n",
        "print('The coefficient is ' model.coef_)\n",
        "print('The intercept is ' model.intercept_)\n",
        "\n",
        "## model plot\n",
        "xfit = np.linspace(-1,11)\n",
        "xfit = xfit[:,np.newaxis]\n",
        "yfit = model.predict(xfit)\n",
        "plt.scatter(x,y)\n",
        "plt.plot(xfit,yfit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1sGhIBw_F_"
      },
      "source": [
        "## 2. Multivariable linear regression with statsmodels\n",
        "\n",
        "- about [statsmodels](https://www.statsmodels.org/stable/index.html): it is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration.\n",
        "\n",
        "- when sucessfully run: \n",
        "  1.   display the sample size (85, 4)\n",
        "  2.   show the descriptives for the continous variable \"Lottery\", \"Literacy\", \"Wealth\" and the categorical variable \"Region\" as:\n",
        "![output 1](https://drive.google.com/uc?export=view&id=1GsrOhd28zEcTpVpCymIrGjrXgbBOQdOw)\n",
        "\n",
        "  3. show the regression summary as:\n",
        "\n",
        "![output 1](https://drive.google.com/uc?export=view&id=1Q6wDT8xzuM79iFlss2KtXJzSLYXcJKVk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpwEoYnQuR55"
      },
      "source": [
        "## load modules and functions\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "## get data\n",
        "ds = sm.datasets.get_rdataset(\"Guerry\", \"HistData\", cache=True)\n",
        "df = ds.data[['Lottery', 'Literacy', 'Wealth', 'Region']].dropna()\n",
        "df.head()\n",
        "\n",
        "## check the sample size\n",
        "df.shape()\n",
        "print('\\n')\n",
        "\n",
        "## statistical summary\n",
        "print(df.describe)\n",
        "print('\\n')\n",
        "print('--> counts for each Region:')\n",
        "print(df('Region').value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WznGc_qpzcFn"
      },
      "source": [
        "## fit the model\n",
        "mod = ols(formula='Lottery ~ Literacy + Wealth + Region')\n",
        "res = mod.fit();\n",
        "print(res.summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPjcCHU3dsQ"
      },
      "source": [
        "## Could you ...\n",
        "write a funtion to run multiple regression analysis in a loop?\n",
        "\n",
        "i.e.,\n",
        "\n",
        "    analysis 1: formula='Lottery ~ Literacy + Region'\n",
        "    analysis 2: formula='Lottery ~ Wealth + Region'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aISayy_44RGQ"
      },
      "source": [
        "def \n",
        "\n",
        "\n",
        "for \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFCRL_y14-yI"
      },
      "source": [
        "#Assignment Two (practice to minimize careless errors)\n",
        "\n",
        "---\n",
        "This assignment covers the basic steps of machine learning with Python. According to the guidelines below, please modify and test the code with the tools you preferred to make it run correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr5zzHuXnbW9"
      },
      "source": [
        "1. Load modules and functions in front\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQOxMSV9y0aO"
      },
      "source": [
        "## load modules and functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIaytqBiz_1Y"
      },
      "source": [
        "2. Define variables to avoid data mis-use (e.g., data path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhdqv7FcvQcu"
      },
      "source": [
        "## Load the dataset\n",
        "from pandas import read_csv\n",
        "dataset = read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\", names=['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpX6ZdcS0DDX"
      },
      "source": [
        "3. Inspect the data before analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZmDKCCAvW-N"
      },
      "source": [
        "## Inspect the data\n",
        "# Peek at the data\n",
        "print ('<====== Display the top 5 samples ======>')\n",
        "print(dataset.head(5))\n",
        "\n",
        "# Dimensions of Dataset\n",
        "print ('\\n')\n",
        "print ('<======   Dimensions of Dataset   ======>')\n",
        "print(dataset.shape)\n",
        "input(\"How many variables in this dataset: \")\n",
        "input(\"How many samples in this dataset: \")\n",
        "\n",
        "# statistical summary\n",
        "print ('\\n')\n",
        "print ('<======   Descriptive Statistics   ======>')\n",
        "print(dataset.describe())\n",
        "# class distribution\n",
        "print(dataset.groupby('class').size())\n",
        "\n",
        "# data visualization: plot the histogram of continuous variables\n",
        "print ('\\n')\n",
        "print ('<===========     Histogram     ===========>')\n",
        "import matplotlib.pyplot as plt\n",
        "# histograms\n",
        "dataset.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iznbIGD2n7Ui"
      },
      "source": [
        "4. Define the training & testing data before modeling\n",
        "- about [cross validation](https://machinelearningmastery.com/introduction-to-random-number-generators-for-machine-learning/): it is a resampling procedure used to evaluate machine learning models on a limited data sample. Usually, we split the data into training and testing. You may hear about leave-one-out, 5-fold, or 10-fold. They are all the procedure that refers to the number of groups that a given data sample is to be split into. \n",
        "\n",
        "    Training set is for build-up the model (or classifier), while test set is the unseen data to apply the model.\n",
        "\n",
        "- about [Random Number Generators](https://machinelearningmastery.com/introduction-to-random-number-generators-for-machine-learning/): \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOQRsSRXvZs1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split-out training and test dataset\n",
        "array = dataset.values\n",
        "X = array[:,0:4] # features\n",
        "y = array[:,4]   # labels\n",
        "\n",
        "# 4/5 samples are training, 1/5 samples are test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwsuuS7-2F2d"
      },
      "source": [
        "- check the sample size of training and test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOm-8jFk2M1y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcvvJa3Cr4vt"
      },
      "source": [
        "5. Compare different algorithms (OPTIONAL)\n",
        "- This part is for you to play if you have additional time\n",
        "- Purpose: \n",
        "> build multiple different models to predict the label (i.e., species from flower measurements); select the best model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgmqrHVQvceS"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "# check algorithms\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('SVM', SVC(gamma='auto')))\n",
        "models\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
        " \n",
        "# Compare Algorithms\n",
        "plt.boxplot(results, labels=names)\n",
        "plt.title('Algorithm Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oejYWXE_tFE_"
      },
      "source": [
        "6. Build model and evaluate with test data: \n",
        "- if run correctly, the accuracy is 0.967"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1jbjugXwZ2K"
      },
      "source": [
        "# Build model with Training data\n",
        "model = SVC(gamma='auto')\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on Test data\n",
        "predictions = model.predict(X_train)\n",
        "\n",
        "# Evaluate predictions\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(round(accuracy_score(Y_train, predictions),3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}